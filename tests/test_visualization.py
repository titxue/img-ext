#!/usr/bin/env python3
"""
å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆæ¨¡å—

ç”Ÿæˆå›¾è¡¨:
- æ€§èƒ½åŸºå‡†æµ‹è¯•å›¾è¡¨
- ç‰¹å¾è´¨é‡åˆ†æå›¾è¡¨
- è®¾å¤‡æ€§èƒ½å¯¹æ¯”å›¾è¡¨
- ç‰¹å¾åˆ†å¸ƒå’Œèšç±»å¯è§†åŒ–
- é™ç»´å¯è§†åŒ–
"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from typing import Dict, List, Any, Tuple
from pathlib import Path
import json
from datetime import datetime
import os
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("husl")


class TestVisualizationGenerator:
    """
    æµ‹è¯•å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå™¨
    """
    
    def __init__(self, output_dir: str = "test_results/visualizations"):
        """
        åˆå§‹åŒ–å¯è§†åŒ–ç”Ÿæˆå™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®å›¾è¡¨æ ·å¼
        self.colors = sns.color_palette("husl", 10)
        self.figsize_large = (12, 8)
        self.figsize_medium = (10, 6)
        self.figsize_small = (8, 6)
        
        print(f"å¯è§†åŒ–è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def plot_performance_benchmark(self, benchmark_data: Dict[str, Any]) -> List[str]:
        """
        ç»˜åˆ¶æ€§èƒ½åŸºå‡†æµ‹è¯•å›¾è¡¨
        
        Args:
            benchmark_data: æ€§èƒ½åŸºå‡†æµ‹è¯•æ•°æ®
            
        Returns:
            List[str]: ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print("\nğŸ“Š ç”Ÿæˆæ€§èƒ½åŸºå‡†æµ‹è¯•å›¾è¡¨")
        
        generated_plots = []
        
        # 1. å•å¼ å›¾ç‰‡å¤„ç†æ—¶é—´å¯¹æ¯”
        if 'single_image_results' in benchmark_data:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=self.figsize_large)
            
            single_results = benchmark_data['single_image_results']
            images = list(single_results.keys())
            times = [single_results[img]['processing_time'] for img in images]
            memory_usage = [single_results[img]['memory_usage']['delta_rss_mb'] for img in images]
            
            # å¤„ç†æ—¶é—´æŸ±çŠ¶å›¾
            bars1 = ax1.bar(range(len(images)), times, color=self.colors[0], alpha=0.7)
            ax1.set_xlabel('æµ‹è¯•å›¾ç‰‡')
            ax1.set_ylabel('å¤„ç†æ—¶é—´ (ç§’)')
            ax1.set_title('å•å¼ å›¾ç‰‡å¤„ç†æ—¶é—´')
            ax1.set_xticks(range(len(images)))
            ax1.set_xticklabels([Path(img).stem for img in images], rotation=45, ha='right')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, time_val in zip(bars1, times):
                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                        f'{time_val:.3f}s', ha='center', va='bottom', fontsize=8)
            
            # å†…å­˜ä½¿ç”¨æŸ±çŠ¶å›¾
            bars2 = ax2.bar(range(len(images)), memory_usage, color=self.colors[1], alpha=0.7)
            ax2.set_xlabel('æµ‹è¯•å›¾ç‰‡')
            ax2.set_ylabel('å†…å­˜å¢é‡ (MB)')
            ax2.set_title('å•å¼ å›¾ç‰‡å†…å­˜ä½¿ç”¨')
            ax2.set_xticks(range(len(images)))
            ax2.set_xticklabels([Path(img).stem for img in images], rotation=45, ha='right')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, mem_val in zip(bars2, memory_usage):
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                        f'{mem_val:.1f}MB', ha='center', va='bottom', fontsize=8)
            
            plt.tight_layout()
            plot_path = self.output_dir / "single_image_performance.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            generated_plots.append(str(plot_path))
            print(f"  âœ… å•å¼ å›¾ç‰‡æ€§èƒ½å›¾è¡¨: {plot_path}")
        
        # 2. æ‰¹é‡å¤„ç†æ€§èƒ½å¯¹æ¯”
        if 'batch_results' in benchmark_data:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=self.figsize_large)
            
            batch_results = benchmark_data['batch_results']
            batch_sizes = list(batch_results.keys())
            processing_times = [batch_results[bs]['processing_time'] for bs in batch_sizes]
            throughputs = [batch_results[bs]['throughput'] for bs in batch_sizes]
            
            # å¤„ç†æ—¶é—´æ›²çº¿
            ax1.plot(batch_sizes, processing_times, marker='o', linewidth=2, markersize=8, color=self.colors[2])
            ax1.set_xlabel('æ‰¹é‡å¤§å°')
            ax1.set_ylabel('å¤„ç†æ—¶é—´ (ç§’)')
            ax1.set_title('æ‰¹é‡å¤„ç†æ—¶é—´')
            ax1.grid(True, alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bs, time_val in zip(batch_sizes, processing_times):
                ax1.annotate(f'{time_val:.3f}s', (bs, time_val), 
                           textcoords="offset points", xytext=(0,10), ha='center')
            
            # ååé‡æ›²çº¿
            ax2.plot(batch_sizes, throughputs, marker='s', linewidth=2, markersize=8, color=self.colors[3])
            ax2.set_xlabel('æ‰¹é‡å¤§å°')
            ax2.set_ylabel('ååé‡ (å›¾ç‰‡/ç§’)')
            ax2.set_title('æ‰¹é‡å¤„ç†ååé‡')
            ax2.grid(True, alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bs, throughput in zip(batch_sizes, throughputs):
                ax2.annotate(f'{throughput:.1f}', (bs, throughput), 
                           textcoords="offset points", xytext=(0,10), ha='center')
            
            plt.tight_layout()
            plot_path = self.output_dir / "batch_performance.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            generated_plots.append(str(plot_path))
            print(f"  âœ… æ‰¹é‡å¤„ç†æ€§èƒ½å›¾è¡¨: {plot_path}")
        
        return generated_plots
    
    def plot_feature_quality_analysis(self, quality_data: Dict[str, Any]) -> List[str]:
        """
        ç»˜åˆ¶ç‰¹å¾è´¨é‡åˆ†æå›¾è¡¨
        
        Args:
            quality_data: ç‰¹å¾è´¨é‡åˆ†ææ•°æ®
            
        Returns:
            List[str]: ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print("\nğŸ“Š ç”Ÿæˆç‰¹å¾è´¨é‡åˆ†æå›¾è¡¨")
        
        generated_plots = []
        
        # 1. ç‰¹å¾åˆ†å¸ƒç»Ÿè®¡
        if 'distribution_analysis' in quality_data:
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
            
            dist_data = quality_data['distribution_analysis']
            overall_stats = dist_data['overall_stats']
            
            # æ•´ä½“ç»Ÿè®¡æŸ±çŠ¶å›¾
            stats_names = ['Mean', 'Std', 'Min', 'Max', 'Median', 'Q25', 'Q75']
            stats_values = [overall_stats['mean'], overall_stats['std'], overall_stats['min'], 
                          overall_stats['max'], overall_stats['median'], 
                          overall_stats['q25'], overall_stats['q75']]
            
            bars = ax1.bar(stats_names, stats_values, color=self.colors[:len(stats_names)], alpha=0.7)
            ax1.set_title('ç‰¹å¾æ•´ä½“ç»Ÿè®¡åˆ†å¸ƒ')
            ax1.set_ylabel('æ•°å€¼')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, val in zip(bars, stats_values):
                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                        f'{val:.3f}', ha='center', va='bottom', fontsize=9)
            
            # ç‰¹å¾ç»´åº¦æ–¹å·®åˆ†å¸ƒ
            if 'dimension_stats' in dist_data:
                dim_stats = dist_data['dimension_stats']
                ax2.hist(dim_stats['std_per_dim'], bins=30, color=self.colors[1], alpha=0.7, edgecolor='black')
                ax2.set_title('ç‰¹å¾ç»´åº¦æ ‡å‡†å·®åˆ†å¸ƒ')
                ax2.set_xlabel('æ ‡å‡†å·®')
                ax2.set_ylabel('é¢‘æ¬¡')
            
            # ç¨€ç–æ€§åˆ†æ
            if 'sparsity' in dist_data:
                sparsity = dist_data['sparsity']
                labels = ['éé›¶å€¼', 'é›¶å€¼', 'è¿‘é›¶å€¼']
                sizes = [1 - sparsity['zero_ratio'], 
                        sparsity['zero_ratio'] - sparsity['near_zero_ratio'],
                        sparsity['near_zero_ratio']]
                colors_pie = [self.colors[0], self.colors[1], self.colors[2]]
                
                ax3.pie(sizes, labels=labels, colors=colors_pie, autopct='%1.1f%%', startangle=90)
                ax3.set_title('ç‰¹å¾ç¨€ç–æ€§åˆ†å¸ƒ')
            
            # æ­£æ€æ€§æ£€éªŒç»“æœ
            if 'normality_tests' in dist_data:
                normality_tests = dist_data['normality_tests']
                dimensions = [t['dimension'] for t in normality_tests]
                p_values = [t['p_value'] for t in normality_tests]
                is_normal = [t['is_normal'] for t in normality_tests]
                
                colors_norm = [self.colors[0] if normal else self.colors[1] for normal in is_normal]
                ax4.bar(dimensions, p_values, color=colors_norm, alpha=0.7)
                ax4.axhline(y=0.05, color='red', linestyle='--', alpha=0.7, label='æ˜¾è‘—æ€§æ°´å¹³ (0.05)')
                ax4.set_title('ç‰¹å¾ç»´åº¦æ­£æ€æ€§æ£€éªŒ')
                ax4.set_xlabel('ç‰¹å¾ç»´åº¦')
                ax4.set_ylabel('På€¼')
                ax4.legend()
            
            plt.tight_layout()
            plot_path = self.output_dir / "feature_distribution_analysis.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            generated_plots.append(str(plot_path))
            print(f"  âœ… ç‰¹å¾åˆ†å¸ƒåˆ†æå›¾è¡¨: {plot_path}")
        
        # 2. ç›¸ä¼¼æ€§åˆ†æçƒ­åŠ›å›¾
        if 'similarity_analysis' in quality_data:
            sim_data = quality_data['similarity_analysis']
            
            if 'cosine_similarity' in sim_data and 'matrix' in sim_data['cosine_similarity']:
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
                
                # ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µçƒ­åŠ›å›¾
                cosine_matrix = np.array(sim_data['cosine_similarity']['matrix'])
                sns.heatmap(cosine_matrix, annot=False, cmap='viridis', ax=ax1, 
                           cbar_kws={'label': 'ä½™å¼¦ç›¸ä¼¼åº¦'})
                ax1.set_title('å›¾ç‰‡é—´ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ')
                ax1.set_xlabel('å›¾ç‰‡ç´¢å¼•')
                ax1.set_ylabel('å›¾ç‰‡ç´¢å¼•')
                
                # ç›¸ä¼¼åº¦åˆ†å¸ƒç›´æ–¹å›¾
                mask = ~np.eye(cosine_matrix.shape[0], dtype=bool)
                similarities = cosine_matrix[mask]
                
                ax2.hist(similarities, bins=30, color=self.colors[2], alpha=0.7, edgecolor='black')
                ax2.axvline(np.mean(similarities), color='red', linestyle='--', 
                           label=f'å¹³å‡å€¼: {np.mean(similarities):.3f}')
                ax2.set_title('ä½™å¼¦ç›¸ä¼¼åº¦åˆ†å¸ƒ')
                ax2.set_xlabel('ä½™å¼¦ç›¸ä¼¼åº¦')
                ax2.set_ylabel('é¢‘æ¬¡')
                ax2.legend()
                
                plt.tight_layout()
                plot_path = self.output_dir / "similarity_analysis.png"
                plt.savefig(plot_path, dpi=300, bbox_inches='tight')
                plt.close()
                generated_plots.append(str(plot_path))
                print(f"  âœ… ç›¸ä¼¼æ€§åˆ†æå›¾è¡¨: {plot_path}")
        
        # 3. èšç±»åˆ†æ
        if 'clustering_analysis' in quality_data:
            cluster_data = quality_data['clustering_analysis']
            
            if 'clustering_results' in cluster_data:
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=self.figsize_large)
                
                clustering_results = cluster_data['clustering_results']
                n_clusters = [r['n_clusters'] for r in clustering_results]
                silhouette_scores = [r['silhouette_score'] for r in clustering_results]
                calinski_scores = [r['calinski_harabasz_score'] for r in clustering_results]
                
                # è½®å»“ç³»æ•°æ›²çº¿
                ax1.plot(n_clusters, silhouette_scores, marker='o', linewidth=2, 
                        markersize=8, color=self.colors[0], label='è½®å»“ç³»æ•°')
                ax1.set_xlabel('èšç±»æ•°é‡')
                ax1.set_ylabel('è½®å»“ç³»æ•°')
                ax1.set_title('èšç±»æ•°é‡ vs è½®å»“ç³»æ•°')
                ax1.grid(True, alpha=0.3)
                ax1.legend()
                
                # æ ‡è®°æœ€ä½³ç‚¹
                best_idx = np.argmax(silhouette_scores)
                ax1.scatter(n_clusters[best_idx], silhouette_scores[best_idx], 
                           color='red', s=100, zorder=5)
                ax1.annotate(f'æœ€ä½³: {n_clusters[best_idx]}', 
                           (n_clusters[best_idx], silhouette_scores[best_idx]),
                           textcoords="offset points", xytext=(10,10), ha='left')
                
                # Calinski-HarabaszæŒ‡æ•°æ›²çº¿
                ax2.plot(n_clusters, calinski_scores, marker='s', linewidth=2, 
                        markersize=8, color=self.colors[1], label='Calinski-HarabaszæŒ‡æ•°')
                ax2.set_xlabel('èšç±»æ•°é‡')
                ax2.set_ylabel('Calinski-HarabaszæŒ‡æ•°')
                ax2.set_title('èšç±»æ•°é‡ vs Calinski-HarabaszæŒ‡æ•°')
                ax2.grid(True, alpha=0.3)
                ax2.legend()
                
                # æ ‡è®°æœ€ä½³ç‚¹
                best_idx = np.argmax(calinski_scores)
                ax2.scatter(n_clusters[best_idx], calinski_scores[best_idx], 
                           color='red', s=100, zorder=5)
                ax2.annotate(f'æœ€ä½³: {n_clusters[best_idx]}', 
                           (n_clusters[best_idx], calinski_scores[best_idx]),
                           textcoords="offset points", xytext=(10,10), ha='left')
                
                plt.tight_layout()
                plot_path = self.output_dir / "clustering_analysis.png"
                plt.savefig(plot_path, dpi=300, bbox_inches='tight')
                plt.close()
                generated_plots.append(str(plot_path))
                print(f"  âœ… èšç±»åˆ†æå›¾è¡¨: {plot_path}")
        
        # 4. é™ç»´å¯è§†åŒ–
        if 'dimensionality_analysis' in quality_data:
            dim_data = quality_data['dimensionality_analysis']
            
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
            
            # PCAæ–¹å·®è§£é‡Šæ¯”
            if 'pca' in dim_data:
                pca_data = dim_data['pca']
                
                # ç´¯ç§¯æ–¹å·®è§£é‡Šæ¯”
                cumulative_var = pca_data['cumulative_variance_ratio']
                ax1.plot(range(1, len(cumulative_var) + 1), cumulative_var, 
                        marker='o', linewidth=2, color=self.colors[0])
                ax1.axhline(y=0.95, color='red', linestyle='--', alpha=0.7, label='95%æ–¹å·®')
                ax1.axhline(y=0.99, color='orange', linestyle='--', alpha=0.7, label='99%æ–¹å·®')
                ax1.set_xlabel('ä¸»æˆåˆ†æ•°é‡')
                ax1.set_ylabel('ç´¯ç§¯æ–¹å·®è§£é‡Šæ¯”')
                ax1.set_title('PCAç´¯ç§¯æ–¹å·®è§£é‡Šæ¯”')
                ax1.legend()
                ax1.grid(True, alpha=0.3)
                
                # å‰20ä¸ªä¸»æˆåˆ†çš„æ–¹å·®è§£é‡Šæ¯”
                explained_var = pca_data['explained_variance_ratio'][:20]
                ax2.bar(range(1, len(explained_var) + 1), explained_var, 
                       color=self.colors[1], alpha=0.7)
                ax2.set_xlabel('ä¸»æˆåˆ†')
                ax2.set_ylabel('æ–¹å·®è§£é‡Šæ¯”')
                ax2.set_title('å‰20ä¸ªä¸»æˆåˆ†æ–¹å·®è§£é‡Šæ¯”')
                
                # PCA 2Då¯è§†åŒ–
                if 'features_2d' in pca_data:
                    pca_2d = np.array(pca_data['features_2d'])
                    scatter = ax3.scatter(pca_2d[:, 0], pca_2d[:, 1], 
                                        c=range(len(pca_2d)), cmap='viridis', alpha=0.7)
                    ax3.set_xlabel('ç¬¬ä¸€ä¸»æˆåˆ†')
                    ax3.set_ylabel('ç¬¬äºŒä¸»æˆåˆ†')
                    ax3.set_title('PCA 2DæŠ•å½±')
                    plt.colorbar(scatter, ax=ax3, label='å›¾ç‰‡ç´¢å¼•')
            
            # t-SNE 2Då¯è§†åŒ–
            if 'tsne' in dim_data and 'features_2d' in dim_data['tsne']:
                tsne_2d = np.array(dim_data['tsne']['features_2d'])
                scatter = ax4.scatter(tsne_2d[:, 0], tsne_2d[:, 1], 
                                    c=range(len(tsne_2d)), cmap='plasma', alpha=0.7)
                ax4.set_xlabel('t-SNEç»´åº¦1')
                ax4.set_ylabel('t-SNEç»´åº¦2')
                ax4.set_title('t-SNE 2DæŠ•å½±')
                plt.colorbar(scatter, ax=ax4, label='å›¾ç‰‡ç´¢å¼•')
            
            plt.tight_layout()
            plot_path = self.output_dir / "dimensionality_analysis.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            generated_plots.append(str(plot_path))
            print(f"  âœ… é™ç»´åˆ†æå›¾è¡¨: {plot_path}")
        
        return generated_plots
    
    def plot_device_comparison(self, comparison_data: Dict[str, Any]) -> List[str]:
        """
        ç»˜åˆ¶è®¾å¤‡æ€§èƒ½å¯¹æ¯”å›¾è¡¨
        
        Args:
            comparison_data: è®¾å¤‡å¯¹æ¯”æ•°æ®
            
        Returns:
            List[str]: ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print("\nğŸ“Š ç”Ÿæˆè®¾å¤‡æ€§èƒ½å¯¹æ¯”å›¾è¡¨")
        
        generated_plots = []
        
        # 1. å•å¼ å›¾ç‰‡æ€§èƒ½å¯¹æ¯”
        if 'single_image_performance' in comparison_data:
            single_perf = comparison_data['single_image_performance']
            devices = list(single_perf.keys())
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=self.figsize_large)
            
            # å¤„ç†æ—¶é—´å¯¹æ¯”
            mean_times = [single_perf[device]['mean_time'] for device in devices]
            std_times = [single_perf[device]['std_time'] for device in devices]
            
            bars1 = ax1.bar(devices, mean_times, yerr=std_times, capsize=5, 
                           color=self.colors[:len(devices)], alpha=0.7)
            ax1.set_ylabel('å¤„ç†æ—¶é—´ (ç§’)')
            ax1.set_title('å•å¼ å›¾ç‰‡å¤„ç†æ—¶é—´å¯¹æ¯”')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, time_val in zip(bars1, mean_times):
                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                        f'{time_val:.4f}s', ha='center', va='bottom')
            
            # å†…å­˜ä½¿ç”¨å¯¹æ¯”
            memory_deltas = [single_perf[device]['memory_usage']['delta_rss_mb'] for device in devices]
            bars2 = ax2.bar(devices, memory_deltas, color=self.colors[:len(devices)], alpha=0.7)
            ax2.set_ylabel('å†…å­˜å¢é‡ (MB)')
            ax2.set_title('å•å¼ å›¾ç‰‡å†…å­˜ä½¿ç”¨å¯¹æ¯”')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, mem_val in zip(bars2, memory_deltas):
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                        f'{mem_val:.1f}MB', ha='center', va='bottom')
            
            plt.tight_layout()
            plot_path = self.output_dir / "device_single_image_comparison.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            generated_plots.append(str(plot_path))
            print(f"  âœ… å•å¼ å›¾ç‰‡è®¾å¤‡å¯¹æ¯”å›¾è¡¨: {plot_path}")
        
        # 2. æ‰¹é‡å¤„ç†æ€§èƒ½å¯¹æ¯”
        if 'batch_performance' in comparison_data:
            batch_perf = comparison_data['batch_performance']
            devices = list(batch_perf.keys())
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=self.figsize_large)
            
            # æ”¶é›†æ‰€æœ‰æ‰¹é‡å¤§å°
            all_batch_sizes = set()
            for device in devices:
                for batch_key in batch_perf[device].keys():
                    batch_size = batch_perf[device][batch_key]['batch_size']
                    all_batch_sizes.add(batch_size)
            
            batch_sizes = sorted(list(all_batch_sizes))
            
            # å¤„ç†æ—¶é—´å¯¹æ¯”
            for i, device in enumerate(devices):
                times = []
                throughputs = []
                
                for bs in batch_sizes:
                    batch_key = f'batch_{bs}'
                    if batch_key in batch_perf[device]:
                        times.append(batch_perf[device][batch_key]['mean_time'])
                        throughputs.append(batch_perf[device][batch_key]['throughput'])
                    else:
                        times.append(np.nan)
                        throughputs.append(np.nan)
                
                ax1.plot(batch_sizes, times, marker='o', linewidth=2, 
                        markersize=6, label=device, color=self.colors[i])
                ax2.plot(batch_sizes, throughputs, marker='s', linewidth=2, 
                        markersize=6, label=device, color=self.colors[i])
            
            ax1.set_xlabel('æ‰¹é‡å¤§å°')
            ax1.set_ylabel('å¤„ç†æ—¶é—´ (ç§’)')
            ax1.set_title('æ‰¹é‡å¤„ç†æ—¶é—´å¯¹æ¯”')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            ax2.set_xlabel('æ‰¹é‡å¤§å°')
            ax2.set_ylabel('ååé‡ (å›¾ç‰‡/ç§’)')
            ax2.set_title('æ‰¹é‡å¤„ç†ååé‡å¯¹æ¯”')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plot_path = self.output_dir / "device_batch_comparison.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            generated_plots.append(str(plot_path))
            print(f"  âœ… æ‰¹é‡å¤„ç†è®¾å¤‡å¯¹æ¯”å›¾è¡¨: {plot_path}")
        
        # 3. ç‰¹å¾ä¸€è‡´æ€§å¯¹æ¯”
        if 'feature_consistency' in comparison_data and not comparison_data['feature_consistency'].get('skipped'):
            consistency_data = comparison_data['feature_consistency']['consistency_results']
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=self.figsize_large)
            
            pairs = list(consistency_data.keys())
            cosine_similarities = [consistency_data[pair]['mean_cosine_similarity'] for pair in pairs]
            l2_distances = [consistency_data[pair]['mean_l2_distance'] for pair in pairs]
            
            # ä½™å¼¦ç›¸ä¼¼åº¦å¯¹æ¯”
            bars1 = ax1.bar(pairs, cosine_similarities, color=self.colors[:len(pairs)], alpha=0.7)
            ax1.set_ylabel('å¹³å‡ä½™å¼¦ç›¸ä¼¼åº¦')
            ax1.set_title('è®¾å¤‡é—´ç‰¹å¾ä½™å¼¦ç›¸ä¼¼åº¦')
            ax1.set_xticklabels(pairs, rotation=45, ha='right')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, sim_val in zip(bars1, cosine_similarities):
                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                        f'{sim_val:.6f}', ha='center', va='bottom', fontsize=9)
            
            # L2è·ç¦»å¯¹æ¯”
            bars2 = ax2.bar(pairs, l2_distances, color=self.colors[:len(pairs)], alpha=0.7)
            ax2.set_ylabel('å¹³å‡L2è·ç¦»')
            ax2.set_title('è®¾å¤‡é—´ç‰¹å¾L2è·ç¦»')
            ax2.set_xticklabels(pairs, rotation=45, ha='right')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, dist_val in zip(bars2, l2_distances):
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                        f'{dist_val:.6f}', ha='center', va='bottom', fontsize=9)
            
            plt.tight_layout()
            plot_path = self.output_dir / "device_consistency_comparison.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            generated_plots.append(str(plot_path))
            print(f"  âœ… è®¾å¤‡ä¸€è‡´æ€§å¯¹æ¯”å›¾è¡¨: {plot_path}")
        
        # 4. æ€§èƒ½æ‘˜è¦é›·è¾¾å›¾
        if 'performance_summary' in comparison_data:
            summary = comparison_data['performance_summary']
            
            if 'single_image_summary' in summary and 'batch_processing_summary' in summary:
                fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
                
                # å‡†å¤‡é›·è¾¾å›¾æ•°æ®
                categories = ['å•å›¾å¤„ç†é€Ÿåº¦', 'æ‰¹é‡ååé‡', 'å†…å­˜æ•ˆç‡', 'ç‰¹å¾ä¸€è‡´æ€§']
                
                devices = comparison_data['available_devices']
                device_scores = {}
                
                for device in devices:
                    scores = []
                    
                    # å•å›¾å¤„ç†é€Ÿåº¦ (è¶Šå¿«è¶Šå¥½ï¼Œå–å€’æ•°å½’ä¸€åŒ–)
                    if device in comparison_data['single_image_performance']:
                        single_time = comparison_data['single_image_performance'][device]['mean_time']
                        speed_score = 1 / single_time
                        scores.append(speed_score)
                    else:
                        scores.append(0)
                    
                    # æ‰¹é‡ååé‡
                    if device in summary['batch_processing_summary']['throughput_by_device']:
                        throughput = summary['batch_processing_summary']['throughput_by_device'][device]
                        scores.append(throughput)
                    else:
                        scores.append(0)
                    
                    # å†…å­˜æ•ˆç‡ (å†…å­˜ä½¿ç”¨è¶Šå°‘è¶Šå¥½)
                    if device in comparison_data['single_image_performance']:
                        memory_usage = comparison_data['single_image_performance'][device]['memory_usage']['delta_rss_mb']
                        memory_score = max(0, 100 - memory_usage)  # ç®€å•çš„å†…å­˜æ•ˆç‡è¯„åˆ†
                        scores.append(memory_score)
                    else:
                        scores.append(0)
                    
                    # ç‰¹å¾ä¸€è‡´æ€§ (å¦‚æœæœ‰çš„è¯)
                    if 'consistency_summary' in summary:
                        consistency_score = summary['consistency_summary']['consistency_score'] * 100
                        scores.append(consistency_score)
                    else:
                        scores.append(100)  # å•è®¾å¤‡æƒ…å†µä¸‹å‡è®¾å®Œå…¨ä¸€è‡´
                    
                    device_scores[device] = scores
                
                # å½’ä¸€åŒ–åˆ†æ•°åˆ°0-100èŒƒå›´
                all_scores = [score for scores in device_scores.values() for score in scores]
                if all_scores:
                    max_score = max(all_scores)
                    min_score = min(all_scores)
                    score_range = max_score - min_score if max_score != min_score else 1
                    
                    for device in device_scores:
                        device_scores[device] = [(score - min_score) / score_range * 100 
                                               for score in device_scores[device]]
                
                # ç»˜åˆ¶é›·è¾¾å›¾
                angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
                angles += angles[:1]  # é—­åˆå›¾å½¢
                
                for i, device in enumerate(devices):
                    values = device_scores[device] + device_scores[device][:1]  # é—­åˆå›¾å½¢
                    ax.plot(angles, values, 'o-', linewidth=2, label=device, color=self.colors[i])
                    ax.fill(angles, values, alpha=0.25, color=self.colors[i])
                
                ax.set_xticks(angles[:-1])
                ax.set_xticklabels(categories)
                ax.set_ylim(0, 100)
                ax.set_title('è®¾å¤‡æ€§èƒ½ç»¼åˆå¯¹æ¯”', size=16, pad=20)
                ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))
                ax.grid(True)
                
                plt.tight_layout()
                plot_path = self.output_dir / "device_performance_radar.png"
                plt.savefig(plot_path, dpi=300, bbox_inches='tight')
                plt.close()
                generated_plots.append(str(plot_path))
                print(f"  âœ… è®¾å¤‡æ€§èƒ½é›·è¾¾å›¾: {plot_path}")
        
        return generated_plots
    
    def generate_all_visualizations(self, benchmark_data: Dict[str, Any] = None,
                                  quality_data: Dict[str, Any] = None,
                                  comparison_data: Dict[str, Any] = None) -> Dict[str, List[str]]:
        """
        ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨
        
        Args:
            benchmark_data: æ€§èƒ½åŸºå‡†æµ‹è¯•æ•°æ®
            quality_data: ç‰¹å¾è´¨é‡åˆ†ææ•°æ®
            comparison_data: è®¾å¤‡å¯¹æ¯”æ•°æ®
            
        Returns:
            Dict[str, List[str]]: å„ç±»å›¾è¡¨çš„æ–‡ä»¶è·¯å¾„
        """
        print("ğŸš€ å¼€å§‹ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨")
        
        all_plots = {
            'performance_benchmark': [],
            'feature_quality': [],
            'device_comparison': []
        }
        
        # ç”Ÿæˆæ€§èƒ½åŸºå‡†æµ‹è¯•å›¾è¡¨
        if benchmark_data:
            all_plots['performance_benchmark'] = self.plot_performance_benchmark(benchmark_data)
        
        # ç”Ÿæˆç‰¹å¾è´¨é‡åˆ†æå›¾è¡¨
        if quality_data:
            all_plots['feature_quality'] = self.plot_feature_quality_analysis(quality_data)
        
        # ç”Ÿæˆè®¾å¤‡å¯¹æ¯”å›¾è¡¨
        if comparison_data:
            all_plots['device_comparison'] = self.plot_device_comparison(comparison_data)
        
        # ç»Ÿè®¡ç”Ÿæˆçš„å›¾è¡¨æ•°é‡
        total_plots = sum(len(plots) for plots in all_plots.values())
        print(f"\nğŸ‰ å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆ! å…±ç”Ÿæˆ {total_plots} ä¸ªå›¾è¡¨")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        
        return all_plots
    
    def save_plot_index(self, all_plots: Dict[str, List[str]]) -> str:
        """
        ä¿å­˜å›¾è¡¨ç´¢å¼•æ–‡ä»¶
        
        Args:
            all_plots: æ‰€æœ‰å›¾è¡¨è·¯å¾„
            
        Returns:
            str: ç´¢å¼•æ–‡ä»¶è·¯å¾„
        """
        index_data = {
            'timestamp': datetime.now().isoformat(),
            'total_plots': sum(len(plots) for plots in all_plots.values()),
            'plots_by_category': all_plots,
            'output_directory': str(self.output_dir)
        }
        
        index_path = self.output_dir / "plot_index.json"
        with open(index_path, 'w', encoding='utf-8') as f:
            json.dump(index_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“‹ å›¾è¡¨ç´¢å¼•å·²ä¿å­˜åˆ°: {index_path}")
        return str(index_path)


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    visualizer = TestVisualizationGenerator()
    
    # è¿™é‡Œå¯ä»¥åŠ è½½å®é™…çš„æµ‹è¯•æ•°æ®å¹¶ç”Ÿæˆå›¾è¡¨
    print("å¯è§†åŒ–ç”Ÿæˆå™¨å·²åˆå§‹åŒ–ï¼Œå¯ä»¥è°ƒç”¨ç›¸åº”æ–¹æ³•ç”Ÿæˆå›¾è¡¨")