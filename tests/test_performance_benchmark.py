#!/usr/bin/env python3
"""
æ€§èƒ½åŸºå‡†æµ‹è¯•æ¨¡å—

æµ‹è¯•å†…å®¹:
- å¤„ç†æ—¶é—´åŸºå‡†æµ‹è¯•
- å†…å­˜ä½¿ç”¨ç›‘æ§
- æ‰¹é‡vså•å¼ å¤„ç†å¯¹æ¯”
- ä¸åŒæ‰¹æ¬¡å¤§å°æ€§èƒ½å¯¹æ¯”
- è®¾å¤‡æ€§èƒ½å¯¹æ¯” (MPS vs CPU)
"""

import time
import psutil
import os
import gc
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict, Tuple, Any
from pathlib import Path
import json
from datetime import datetime

import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from feature_extractor import FeatureExtractor


class PerformanceBenchmark:
    """
    æ€§èƒ½åŸºå‡†æµ‹è¯•ç±»
    """
    
    def __init__(self, test_images_dir: str):
        """
        åˆå§‹åŒ–æ€§èƒ½æµ‹è¯•
        
        Args:
            test_images_dir: æµ‹è¯•å›¾ç‰‡ç›®å½•
        """
        self.test_images_dir = Path(test_images_dir)
        self.test_images = self._load_test_images()
        self.results = {}
        
        print(f"åŠ è½½äº† {len(self.test_images)} å¼ æµ‹è¯•å›¾ç‰‡")
    
    def _load_test_images(self) -> List[str]:
        """
        åŠ è½½æµ‹è¯•å›¾ç‰‡è·¯å¾„
        
        Returns:
            List[str]: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        """
        image_extensions = {'.jpg', '.jpeg', '.png', '.webp'}
        images = []
        
        for ext in image_extensions:
            images.extend(self.test_images_dir.glob(f'*{ext}'))
            images.extend(self.test_images_dir.glob(f'*{ext.upper()}'))
        
        return [str(img) for img in images]
    
    def _get_memory_usage(self) -> float:
        """
        è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡ (MB)
        
        Returns:
            float: å†…å­˜ä½¿ç”¨é‡
        """
        process = psutil.Process(os.getpid())
        return process.memory_info().rss / 1024 / 1024
    
    def _measure_time_and_memory(self, func, *args, **kwargs) -> Tuple[Any, float, float, float]:
        """
        æµ‹é‡å‡½æ•°æ‰§è¡Œæ—¶é—´å’Œå†…å­˜ä½¿ç”¨
        
        Args:
            func: è¦æµ‹é‡çš„å‡½æ•°
            *args: å‡½æ•°å‚æ•°
            **kwargs: å‡½æ•°å…³é”®å­—å‚æ•°
            
        Returns:
            Tuple[Any, float, float, float]: (ç»“æœ, æ‰§è¡Œæ—¶é—´, å¼€å§‹å†…å­˜, ç»“æŸå†…å­˜)
        """
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        start_memory = self._get_memory_usage()
        start_time = time.time()
        
        result = func(*args, **kwargs)
        
        end_time = time.time()
        end_memory = self._get_memory_usage()
        
        execution_time = end_time - start_time
        
        return result, execution_time, start_memory, end_memory
    
    def test_single_image_performance(self, extractor: FeatureExtractor, num_runs: int = 10) -> Dict[str, Any]:
        """
        æµ‹è¯•å•å¼ å›¾ç‰‡å¤„ç†æ€§èƒ½
        
        Args:
            extractor: ç‰¹å¾æå–å™¨
            num_runs: è¿è¡Œæ¬¡æ•°
            
        Returns:
            Dict[str, Any]: æ€§èƒ½æµ‹è¯•ç»“æœ
        """
        print(f"\nğŸ” æµ‹è¯•å•å¼ å›¾ç‰‡å¤„ç†æ€§èƒ½ (è®¾å¤‡: {extractor.device})")
        
        times = []
        memory_usage = []
        
        # é€‰æ‹©å‰num_runså¼ å›¾ç‰‡è¿›è¡Œæµ‹è¯•
        test_images = self.test_images[:min(num_runs, len(self.test_images))]
        
        for i, img_path in enumerate(test_images):
            print(f"  å¤„ç†å›¾ç‰‡ {i+1}/{len(test_images)}: {Path(img_path).name}")
            
            _, exec_time, start_mem, end_mem = self._measure_time_and_memory(
                extractor.extract_features, img_path
            )
            
            times.append(exec_time)
            memory_usage.append(end_mem - start_mem)
        
        results = {
            'device': str(extractor.device),
            'num_images': len(test_images),
            'avg_time': np.mean(times),
            'std_time': np.std(times),
            'min_time': np.min(times),
            'max_time': np.max(times),
            'avg_memory': np.mean(memory_usage),
            'std_memory': np.std(memory_usage),
            'times': times,
            'memory_usage': memory_usage
        }
        
        print(f"  âœ… å¹³å‡å¤„ç†æ—¶é—´: {results['avg_time']:.4f}s Â± {results['std_time']:.4f}s")
        print(f"  ğŸ“Š å†…å­˜ä½¿ç”¨: {results['avg_memory']:.2f}MB Â± {results['std_memory']:.2f}MB")
        
        return results
    
    def test_batch_performance(self, extractor: FeatureExtractor, batch_sizes: List[int] = None) -> Dict[str, Any]:
        """
        æµ‹è¯•æ‰¹é‡å¤„ç†æ€§èƒ½
        
        Args:
            extractor: ç‰¹å¾æå–å™¨
            batch_sizes: æ‰¹æ¬¡å¤§å°åˆ—è¡¨
            
        Returns:
            Dict[str, Any]: æ‰¹é‡å¤„ç†æ€§èƒ½ç»“æœ
        """
        if batch_sizes is None:
            batch_sizes = [1, 4, 8, 16, 32]
        
        print(f"\nğŸ” æµ‹è¯•æ‰¹é‡å¤„ç†æ€§èƒ½ (è®¾å¤‡: {extractor.device})")
        
        results = {
            'device': str(extractor.device),
            'batch_results': {}
        }
        
        # ä½¿ç”¨å‰32å¼ å›¾ç‰‡è¿›è¡Œæ‰¹é‡æµ‹è¯•
        test_images = self.test_images[:min(32, len(self.test_images))]
        
        for batch_size in batch_sizes:
            print(f"  æµ‹è¯•æ‰¹æ¬¡å¤§å°: {batch_size}")
            
            _, exec_time, start_mem, end_mem = self._measure_time_and_memory(
                extractor.extract_features_batch, test_images, batch_size
            )
            
            # è®¡ç®—æ¯å¼ å›¾ç‰‡çš„å¹³å‡å¤„ç†æ—¶é—´
            time_per_image = exec_time / len(test_images)
            memory_usage = end_mem - start_mem
            
            results['batch_results'][batch_size] = {
                'total_time': exec_time,
                'time_per_image': time_per_image,
                'memory_usage': memory_usage,
                'throughput': len(test_images) / exec_time  # å›¾ç‰‡/ç§’
            }
            
            print(f"    â±ï¸  æ€»æ—¶é—´: {exec_time:.4f}s")
            print(f"    ğŸ“ˆ æ¯å¼ å›¾ç‰‡: {time_per_image:.4f}s")
            print(f"    ğŸš€ ååé‡: {results['batch_results'][batch_size]['throughput']:.2f} å›¾ç‰‡/ç§’")
            print(f"    ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory_usage:.2f}MB")
        
        return results
    
    def compare_single_vs_batch(self, extractor: FeatureExtractor, num_images: int = 20) -> Dict[str, Any]:
        """
        å¯¹æ¯”å•å¼ å¤„ç†vsæ‰¹é‡å¤„ç†æ€§èƒ½
        
        Args:
            extractor: ç‰¹å¾æå–å™¨
            num_images: æµ‹è¯•å›¾ç‰‡æ•°é‡
            
        Returns:
            Dict[str, Any]: å¯¹æ¯”ç»“æœ
        """
        print(f"\nğŸ” å¯¹æ¯”å•å¼ vsæ‰¹é‡å¤„ç†æ€§èƒ½ (è®¾å¤‡: {extractor.device})")
        
        test_images = self.test_images[:min(num_images, len(self.test_images))]
        
        # æµ‹è¯•å•å¼ å¤„ç†
        print("  æµ‹è¯•å•å¼ å¤„ç†...")
        single_start_time = time.time()
        single_start_mem = self._get_memory_usage()
        
        for img_path in test_images:
            extractor.extract_features(img_path)
        
        single_end_time = time.time()
        single_end_mem = self._get_memory_usage()
        
        single_total_time = single_end_time - single_start_time
        single_memory = single_end_mem - single_start_mem
        
        # æµ‹è¯•æ‰¹é‡å¤„ç†
        print("  æµ‹è¯•æ‰¹é‡å¤„ç†...")
        _, batch_total_time, batch_start_mem, batch_end_mem = self._measure_time_and_memory(
            extractor.extract_features_batch, test_images, 16
        )
        
        batch_memory = batch_end_mem - batch_start_mem
        
        # è®¡ç®—æ€§èƒ½æå‡
        time_speedup = single_total_time / batch_total_time
        memory_ratio = batch_memory / single_memory if single_memory > 0 else 1
        
        results = {
            'device': str(extractor.device),
            'num_images': len(test_images),
            'single_processing': {
                'total_time': single_total_time,
                'time_per_image': single_total_time / len(test_images),
                'memory_usage': single_memory
            },
            'batch_processing': {
                'total_time': batch_total_time,
                'time_per_image': batch_total_time / len(test_images),
                'memory_usage': batch_memory
            },
            'performance_gain': {
                'time_speedup': time_speedup,
                'memory_ratio': memory_ratio
            }
        }
        
        print(f"  âœ… å•å¼ å¤„ç†æ€»æ—¶é—´: {single_total_time:.4f}s")
        print(f"  âœ… æ‰¹é‡å¤„ç†æ€»æ—¶é—´: {batch_total_time:.4f}s")
        print(f"  ğŸš€ æ€§èƒ½æå‡: {time_speedup:.2f}x")
        print(f"  ğŸ’¾ å†…å­˜æ¯”ç‡: {memory_ratio:.2f}x")
        
        return results
    
    def run_comprehensive_benchmark(self, devices: List[str] = None) -> Dict[str, Any]:
        """
        è¿è¡Œå…¨é¢çš„æ€§èƒ½åŸºå‡†æµ‹è¯•
        
        Args:
            devices: è¦æµ‹è¯•çš„è®¾å¤‡åˆ—è¡¨
            
        Returns:
            Dict[str, Any]: å®Œæ•´çš„åŸºå‡†æµ‹è¯•ç»“æœ
        """
        if devices is None:
            devices = ['auto']  # é»˜è®¤ä½¿ç”¨è‡ªåŠ¨è®¾å¤‡é€‰æ‹©
        
        print("ğŸš€ å¼€å§‹å…¨é¢æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print(f"ğŸ“Š æµ‹è¯•å›¾ç‰‡æ•°é‡: {len(self.test_images)}")
        print(f"ğŸ–¥ï¸  æµ‹è¯•è®¾å¤‡: {devices}")
        
        all_results = {
            'timestamp': datetime.now().isoformat(),
            'test_images_count': len(self.test_images),
            'devices_tested': [],
            'results': {}
        }
        
        for device in devices:
            print(f"\n{'='*50}")
            print(f"ğŸ–¥ï¸  æµ‹è¯•è®¾å¤‡: {device}")
            print(f"{'='*50}")
            
            try:
                # åˆ›å»ºç‰¹å¾æå–å™¨
                extractor = FeatureExtractor(device=device)
                device_name = str(extractor.device)
                all_results['devices_tested'].append(device_name)
                
                # è®¾å¤‡ä¿¡æ¯
                device_info = extractor.get_device_info()
                print(f"ğŸ“‹ è®¾å¤‡ä¿¡æ¯: {device_info}")
                
                # è¿è¡Œå„é¡¹æµ‹è¯•
                device_results = {
                    'device_info': device_info,
                    'single_image_performance': self.test_single_image_performance(extractor),
                    'batch_performance': self.test_batch_performance(extractor),
                    'single_vs_batch_comparison': self.compare_single_vs_batch(extractor)
                }
                
                all_results['results'][device_name] = device_results
                
            except Exception as e:
                print(f"âŒ è®¾å¤‡ {device} æµ‹è¯•å¤±è´¥: {e}")
                continue
        
        # ä¿å­˜ç»“æœ
        self.results = all_results
        return all_results
    
    def save_results(self, output_path: str = None) -> str:
        """
        ä¿å­˜æµ‹è¯•ç»“æœåˆ°JSONæ–‡ä»¶
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"performance_benchmark_{timestamp}.json"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        return output_path


if __name__ == "__main__":
    # è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
    test_images_dir = "test_data/real_images"
    
    if not os.path.exists(test_images_dir):
        print(f"âŒ æµ‹è¯•å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {test_images_dir}")
        exit(1)
    
    # åˆ›å»ºåŸºå‡†æµ‹è¯•å®ä¾‹
    benchmark = PerformanceBenchmark(test_images_dir)
    
    # è¿è¡Œæµ‹è¯•
    results = benchmark.run_comprehensive_benchmark(['auto', 'cpu'])
    
    # ä¿å­˜ç»“æœ
    benchmark.save_results()
    
    print("\nğŸ‰ æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ!")