#!/usr/bin/env python3
"""
è®¾å¤‡æ€§èƒ½å¯¹æ¯”æµ‹è¯•æ¨¡å—

å¯¹æ¯”å†…å®¹:
- MPS vs CPU å¤„ç†æ—¶é—´å¯¹æ¯”
- å†…å­˜ä½¿ç”¨å¯¹æ¯”
- æ‰¹é‡å¤„ç†æ€§èƒ½å¯¹æ¯”
- ç‰¹å¾è´¨é‡ä¸€è‡´æ€§éªŒè¯
- è®¾å¤‡åˆ‡æ¢å¼€é”€æµ‹è¯•
"""

import time
import psutil
import numpy as np
import torch
from typing import Dict, List, Any, Tuple
from pathlib import Path
import json
from datetime import datetime
import os
import sys
from sklearn.metrics.pairwise import cosine_similarity

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from feature_extractor import FeatureExtractor


class DevicePerformanceComparator:
    """
    è®¾å¤‡æ€§èƒ½å¯¹æ¯”å™¨
    """
    
    def __init__(self, test_images_dir: str):
        """
        åˆå§‹åŒ–è®¾å¤‡æ€§èƒ½å¯¹æ¯”å™¨
        
        Args:
            test_images_dir: æµ‹è¯•å›¾ç‰‡ç›®å½•
        """
        self.test_images_dir = Path(test_images_dir)
        self.test_images = self._load_test_images()
        self.results = {}
        
        # æ£€æŸ¥å¯ç”¨è®¾å¤‡
        self.available_devices = self._check_available_devices()
        
        print(f"åŠ è½½äº† {len(self.test_images)} å¼ æµ‹è¯•å›¾ç‰‡")
        print(f"å¯ç”¨è®¾å¤‡: {', '.join(self.available_devices)}")
    
    def _load_test_images(self) -> List[str]:
        """
        åŠ è½½æµ‹è¯•å›¾ç‰‡è·¯å¾„
        
        Returns:
            List[str]: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        """
        image_extensions = {'.jpg', '.jpeg', '.png', '.webp'}
        images = []
        
        for ext in image_extensions:
            images.extend(self.test_images_dir.glob(f'*{ext}'))
            images.extend(self.test_images_dir.glob(f'*{ext.upper()}'))
        
        return [str(img) for img in images[:20]]  # é™åˆ¶ä¸º20å¼ å›¾ç‰‡ä»¥åŠ å¿«æµ‹è¯•
    
    def _check_available_devices(self) -> List[str]:
        """
        æ£€æŸ¥å¯ç”¨çš„è®¾å¤‡
        
        Returns:
            List[str]: å¯ç”¨è®¾å¤‡åˆ—è¡¨
        """
        devices = ['cpu']
        
        # æ£€æŸ¥CUDA
        if torch.cuda.is_available():
            devices.append('cuda')
        
        # æ£€æŸ¥MPS (Mac M-series)
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            devices.append('mps')
        
        return devices
    
    def _get_memory_usage(self) -> Dict[str, float]:
        """
        è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ
        
        Returns:
            Dict[str, float]: å†…å­˜ä½¿ç”¨ä¿¡æ¯
        """
        process = psutil.Process()
        memory_info = process.memory_info()
        
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,  # ç‰©ç†å†…å­˜ (MB)
            'vms_mb': memory_info.vms / 1024 / 1024,  # è™šæ‹Ÿå†…å­˜ (MB)
            'percent': process.memory_percent()        # å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯”
        }
    
    def benchmark_single_image_performance(self, image_path: str) -> Dict[str, Any]:
        """
        å•å¼ å›¾ç‰‡æ€§èƒ½åŸºå‡†æµ‹è¯•
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            Dict[str, Any]: å„è®¾å¤‡æ€§èƒ½ç»“æœ
        """
        print(f"\nğŸ–¼ï¸  å•å¼ å›¾ç‰‡æ€§èƒ½æµ‹è¯•: {Path(image_path).name}")
        
        results = {}
        
        for device in self.available_devices:
            print(f"  æµ‹è¯•è®¾å¤‡: {device}")
            
            # åˆ›å»ºç‰¹å¾æå–å™¨
            extractor = FeatureExtractor(device=device)
            
            # é¢„çƒ­ (é¿å…é¦–æ¬¡è¿è¡Œçš„åˆå§‹åŒ–å¼€é”€)
            _ = extractor.extract_features(image_path)
            
            # è®°å½•åˆå§‹å†…å­˜
            initial_memory = self._get_memory_usage()
            
            # å¤šæ¬¡è¿è¡Œå–å¹³å‡å€¼
            times = []
            for _ in range(5):
                start_time = time.perf_counter()
                features = extractor.extract_features(image_path)
                end_time = time.perf_counter()
                times.append(end_time - start_time)
            
            # è®°å½•å³°å€¼å†…å­˜
            peak_memory = self._get_memory_usage()
            
            results[device] = {
                'mean_time': np.mean(times),
                'std_time': np.std(times),
                'min_time': np.min(times),
                'max_time': np.max(times),
                'features_shape': features.shape,
                'memory_usage': {
                    'initial': initial_memory,
                    'peak': peak_memory,
                    'delta_rss_mb': peak_memory['rss_mb'] - initial_memory['rss_mb']
                }
            }
            
            print(f"    å¹³å‡æ—¶é—´: {results[device]['mean_time']:.4f}s Â± {results[device]['std_time']:.4f}s")
            print(f"    å†…å­˜å¢é‡: {results[device]['memory_usage']['delta_rss_mb']:.2f}MB")
        
        return results
    
    def benchmark_batch_performance(self, batch_sizes: List[int] = None) -> Dict[str, Any]:
        """
        æ‰¹é‡å¤„ç†æ€§èƒ½åŸºå‡†æµ‹è¯•
        
        Args:
            batch_sizes: æ‰¹é‡å¤§å°åˆ—è¡¨
            
        Returns:
            Dict[str, Any]: å„è®¾å¤‡æ‰¹é‡å¤„ç†æ€§èƒ½ç»“æœ
        """
        if batch_sizes is None:
            batch_sizes = [1, 4, 8, 16]
        
        print(f"\nğŸ“¦ æ‰¹é‡å¤„ç†æ€§èƒ½æµ‹è¯•")
        
        results = {}
        
        for device in self.available_devices:
            print(f"  æµ‹è¯•è®¾å¤‡: {device}")
            device_results = {}
            
            extractor = FeatureExtractor(device=device)
            
            for batch_size in batch_sizes:
                if batch_size > len(self.test_images):
                    continue
                
                print(f"    æ‰¹é‡å¤§å°: {batch_size}")
                
                # é€‰æ‹©æµ‹è¯•å›¾ç‰‡
                test_batch = self.test_images[:batch_size]
                
                # é¢„çƒ­
                _ = extractor.extract_features_batch(test_batch, batch_size=batch_size)
                
                # è®°å½•åˆå§‹å†…å­˜
                initial_memory = self._get_memory_usage()
                
                # å¤šæ¬¡è¿è¡Œå–å¹³å‡å€¼
                times = []
                for _ in range(3):
                    start_time = time.perf_counter()
                    features = extractor.extract_features_batch(test_batch, batch_size=batch_size)
                    end_time = time.perf_counter()
                    times.append(end_time - start_time)
                
                # è®°å½•å³°å€¼å†…å­˜
                peak_memory = self._get_memory_usage()
                
                device_results[f'batch_{batch_size}'] = {
                    'batch_size': batch_size,
                    'mean_time': np.mean(times),
                    'std_time': np.std(times),
                    'throughput': batch_size / np.mean(times),  # å›¾ç‰‡/ç§’
                    'time_per_image': np.mean(times) / batch_size,
                    'features_shape': features.shape,
                    'memory_usage': {
                        'initial': initial_memory,
                        'peak': peak_memory,
                        'delta_rss_mb': peak_memory['rss_mb'] - initial_memory['rss_mb']
                    }
                }
                
                print(f"      å¹³å‡æ—¶é—´: {device_results[f'batch_{batch_size}']['mean_time']:.4f}s")
                print(f"      ååé‡: {device_results[f'batch_{batch_size}']['throughput']:.2f} å›¾ç‰‡/ç§’")
                print(f"      å•å›¾æ—¶é—´: {device_results[f'batch_{batch_size}']['time_per_image']:.4f}s")
            
            results[device] = device_results
        
        return results
    
    def test_feature_consistency(self, num_test_images: int = 5) -> Dict[str, Any]:
        """
        æµ‹è¯•ä¸åŒè®¾å¤‡é—´ç‰¹å¾ä¸€è‡´æ€§
        
        Args:
            num_test_images: æµ‹è¯•å›¾ç‰‡æ•°é‡
            
        Returns:
            Dict[str, Any]: ç‰¹å¾ä¸€è‡´æ€§æµ‹è¯•ç»“æœ
        """
        print(f"\nğŸ” ç‰¹å¾ä¸€è‡´æ€§æµ‹è¯• (æµ‹è¯• {num_test_images} å¼ å›¾ç‰‡)")
        
        if len(self.available_devices) < 2:
            print("  âš ï¸  åªæœ‰ä¸€ä¸ªè®¾å¤‡å¯ç”¨ï¼Œè·³è¿‡ä¸€è‡´æ€§æµ‹è¯•")
            return {'skipped': True, 'reason': 'Only one device available'}
        
        test_images = self.test_images[:num_test_images]
        device_features = {}
        
        # åœ¨æ¯ä¸ªè®¾å¤‡ä¸Šæå–ç‰¹å¾
        for device in self.available_devices:
            print(f"  åœ¨ {device} ä¸Šæå–ç‰¹å¾...")
            extractor = FeatureExtractor(device=device)
            features = extractor.extract_features_batch(test_images, batch_size=4)
            device_features[device] = features
        
        # è®¡ç®—è®¾å¤‡é—´ç‰¹å¾ç›¸ä¼¼æ€§
        consistency_results = {}
        device_pairs = []
        
        for i, device1 in enumerate(self.available_devices):
            for j, device2 in enumerate(self.available_devices[i+1:], i+1):
                pair_name = f"{device1}_vs_{device2}"
                device_pairs.append((device1, device2))
                
                features1 = device_features[device1]
                features2 = device_features[device2]
                
                # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                similarities = []
                for k in range(len(features1)):
                    sim = cosine_similarity([features1[k]], [features2[k]])[0][0]
                    similarities.append(sim)
                
                # è®¡ç®—L2è·ç¦»
                l2_distances = []
                for k in range(len(features1)):
                    dist = np.linalg.norm(features1[k] - features2[k])
                    l2_distances.append(dist)
                
                consistency_results[pair_name] = {
                    'cosine_similarities': similarities,
                    'mean_cosine_similarity': np.mean(similarities),
                    'std_cosine_similarity': np.std(similarities),
                    'min_cosine_similarity': np.min(similarities),
                    'l2_distances': l2_distances,
                    'mean_l2_distance': np.mean(l2_distances),
                    'std_l2_distance': np.std(l2_distances),
                    'max_l2_distance': np.max(l2_distances)
                }
                
                print(f"  {pair_name}:")
                print(f"    å¹³å‡ä½™å¼¦ç›¸ä¼¼åº¦: {consistency_results[pair_name]['mean_cosine_similarity']:.6f} Â± {consistency_results[pair_name]['std_cosine_similarity']:.6f}")
                print(f"    å¹³å‡L2è·ç¦»: {consistency_results[pair_name]['mean_l2_distance']:.6f} Â± {consistency_results[pair_name]['std_l2_distance']:.6f}")
        
        return {
            'device_pairs': device_pairs,
            'consistency_results': consistency_results,
            'num_test_images': num_test_images
        }
    
    def test_device_switching_overhead(self) -> Dict[str, Any]:
        """
        æµ‹è¯•è®¾å¤‡åˆ‡æ¢å¼€é”€
        
        Returns:
            Dict[str, Any]: è®¾å¤‡åˆ‡æ¢å¼€é”€æµ‹è¯•ç»“æœ
        """
        print("\nğŸ”„ è®¾å¤‡åˆ‡æ¢å¼€é”€æµ‹è¯•")
        
        if len(self.available_devices) < 2:
            print("  âš ï¸  åªæœ‰ä¸€ä¸ªè®¾å¤‡å¯ç”¨ï¼Œè·³è¿‡åˆ‡æ¢å¼€é”€æµ‹è¯•")
            return {'skipped': True, 'reason': 'Only one device available'}
        
        test_image = self.test_images[0]
        switching_results = []
        
        # æµ‹è¯•è®¾å¤‡é—´åˆ‡æ¢çš„å¼€é”€
        for i in range(len(self.available_devices)):
            for j in range(len(self.available_devices)):
                if i == j:
                    continue
                
                device1 = self.available_devices[i]
                device2 = self.available_devices[j]
                
                print(f"  æµ‹è¯•åˆ‡æ¢: {device1} -> {device2}")
                
                # åœ¨ç¬¬ä¸€ä¸ªè®¾å¤‡ä¸Šåˆå§‹åŒ–
                extractor1 = FeatureExtractor(device=device1)
                _ = extractor1.extract_features(test_image)  # é¢„çƒ­
                
                # è®°å½•åˆ‡æ¢æ—¶é—´
                switch_start = time.perf_counter()
                extractor2 = FeatureExtractor(device=device2)
                _ = extractor2.extract_features(test_image)  # é¦–æ¬¡è¿è¡Œ
                switch_end = time.perf_counter()
                
                switch_time = switch_end - switch_start
                
                # æµ‹è¯•åˆ‡æ¢åçš„ç¨³å®šæ€§èƒ½
                stable_times = []
                for _ in range(3):
                    start_time = time.perf_counter()
                    _ = extractor2.extract_features(test_image)
                    end_time = time.perf_counter()
                    stable_times.append(end_time - start_time)
                
                switching_results.append({
                    'from_device': device1,
                    'to_device': device2,
                    'switch_time': switch_time,
                    'stable_mean_time': np.mean(stable_times),
                    'stable_std_time': np.std(stable_times)
                })
                
                print(f"    åˆ‡æ¢æ—¶é—´: {switch_time:.4f}s")
                print(f"    ç¨³å®šåæ—¶é—´: {np.mean(stable_times):.4f}s Â± {np.std(stable_times):.4f}s")
        
        return {
            'switching_results': switching_results,
            'mean_switch_time': np.mean([r['switch_time'] for r in switching_results]),
            'max_switch_time': np.max([r['switch_time'] for r in switching_results])
        }
    
    def generate_performance_summary(self) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ€§èƒ½å¯¹æ¯”æ‘˜è¦
        
        Returns:
            Dict[str, Any]: æ€§èƒ½æ‘˜è¦
        """
        if not self.results:
            return {'error': 'No results available. Run comprehensive comparison first.'}
        
        summary = {
            'available_devices': self.available_devices,
            'test_images_count': len(self.test_images)
        }
        
        # å•å¼ å›¾ç‰‡æ€§èƒ½æ‘˜è¦
        if 'single_image_performance' in self.results:
            single_perf = self.results['single_image_performance']
            fastest_device = min(single_perf.keys(), key=lambda d: single_perf[d]['mean_time'])
            slowest_device = max(single_perf.keys(), key=lambda d: single_perf[d]['mean_time'])
            
            summary['single_image_summary'] = {
                'fastest_device': fastest_device,
                'fastest_time': single_perf[fastest_device]['mean_time'],
                'slowest_device': slowest_device,
                'slowest_time': single_perf[slowest_device]['mean_time'],
                'speedup_ratio': single_perf[slowest_device]['mean_time'] / single_perf[fastest_device]['mean_time']
            }
        
        # æ‰¹é‡å¤„ç†æ€§èƒ½æ‘˜è¦
        if 'batch_performance' in self.results:
            batch_perf = self.results['batch_performance']
            best_throughput = {}
            
            for device in batch_perf:
                device_throughputs = [batch_perf[device][batch]['throughput'] 
                                    for batch in batch_perf[device]]
                best_throughput[device] = max(device_throughputs)
            
            fastest_batch_device = max(best_throughput.keys(), key=lambda d: best_throughput[d])
            
            summary['batch_processing_summary'] = {
                'best_throughput_device': fastest_batch_device,
                'best_throughput': best_throughput[fastest_batch_device],
                'throughput_by_device': best_throughput
            }
        
        # ç‰¹å¾ä¸€è‡´æ€§æ‘˜è¦
        if 'feature_consistency' in self.results and not self.results['feature_consistency'].get('skipped'):
            consistency = self.results['feature_consistency']['consistency_results']
            avg_similarities = [result['mean_cosine_similarity'] for result in consistency.values()]
            
            summary['consistency_summary'] = {
                'mean_similarity': np.mean(avg_similarities),
                'min_similarity': np.min(avg_similarities),
                'consistency_score': np.mean(avg_similarities)  # è¶Šæ¥è¿‘1è¶Šå¥½
            }
        
        return summary
    
    def run_comprehensive_comparison(self) -> Dict[str, Any]:
        """
        è¿è¡Œå…¨é¢çš„è®¾å¤‡æ€§èƒ½å¯¹æ¯”
        
        Returns:
            Dict[str, Any]: å®Œæ•´çš„å¯¹æ¯”ç»“æœ
        """
        print("ğŸš€ å¼€å§‹å…¨é¢è®¾å¤‡æ€§èƒ½å¯¹æ¯”")
        print(f"ğŸ“Š æµ‹è¯•å›¾ç‰‡æ•°é‡: {len(self.test_images)}")
        print(f"ğŸ–¥ï¸  å¯ç”¨è®¾å¤‡: {', '.join(self.available_devices)}")
        
        all_results = {
            'timestamp': datetime.now().isoformat(),
            'available_devices': self.available_devices,
            'test_images_count': len(self.test_images),
            'system_info': {
                'cpu_count': psutil.cpu_count(),
                'memory_total_gb': psutil.virtual_memory().total / 1024**3,
                'torch_version': torch.__version__
            }
        }
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        if self.test_images:
            all_results['single_image_performance'] = self.benchmark_single_image_performance(self.test_images[0])
        
        all_results['batch_performance'] = self.benchmark_batch_performance()
        all_results['feature_consistency'] = self.test_feature_consistency()
        all_results['device_switching'] = self.test_device_switching_overhead()
        
        # ç”Ÿæˆæ‘˜è¦
        self.results = all_results
        all_results['performance_summary'] = self.generate_performance_summary()
        
        return all_results
    
    def save_results(self, output_path: str = None) -> str:
        """
        ä¿å­˜å¯¹æ¯”ç»“æœåˆ°JSONæ–‡ä»¶
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"device_performance_comparison_{timestamp}.json"
        
        # å¤„ç†numpyæ•°ç»„ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
        def convert_numpy(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, dict):
                return {key: convert_numpy(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy(item) for item in obj]
            else:
                return obj
        
        serializable_results = convert_numpy(self.results)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“ å¯¹æ¯”ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        return output_path


if __name__ == "__main__":
    # è¿è¡Œè®¾å¤‡æ€§èƒ½å¯¹æ¯”
    test_images_dir = "test_data/real_images"
    
    if not os.path.exists(test_images_dir):
        print(f"âŒ æµ‹è¯•å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {test_images_dir}")
        exit(1)
    
    # åˆ›å»ºå¯¹æ¯”å™¨
    comparator = DevicePerformanceComparator(test_images_dir)
    
    # è¿è¡Œå¯¹æ¯”
    results = comparator.run_comprehensive_comparison()
    
    # ä¿å­˜ç»“æœ
    comparator.save_results()
    
    print("\nğŸ‰ è®¾å¤‡æ€§èƒ½å¯¹æ¯”å®Œæˆ!")