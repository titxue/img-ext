#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§ä½¿ç”¨ç¤ºä¾‹ - å›¾åƒç›¸ä¼¼åº¦æœç´¢å’Œèšç±»

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨FeatureExtractorè¿›è¡Œæ›´é«˜çº§çš„åº”ç”¨ï¼š
1. å›¾åƒç›¸ä¼¼åº¦æœç´¢
2. å›¾åƒèšç±»
3. ç‰¹å¾å‘é‡çš„ä¿å­˜å’ŒåŠ è½½
4. å¤§è§„æ¨¡å›¾åƒå¤„ç†
"""

import sys
import os
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import torch
import time
import json
from typing import List, Tuple, Dict
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from feature_extractor import FeatureExtractor


class ImageSimilaritySearch:
    """å›¾åƒç›¸ä¼¼åº¦æœç´¢ç±»"""
    
    def __init__(self, extractor: FeatureExtractor):
        self.extractor = extractor
        self.image_database = []
        self.feature_database = []
        self.metadata_database = []
    
    def add_image(self, image: Image.Image, metadata: Dict = None):
        """æ·»åŠ å›¾åƒåˆ°æ•°æ®åº“"""
        features = self.extractor.extract_features(image)
        
        self.image_database.append(image)
        self.feature_database.append(features.cpu().numpy())
        self.metadata_database.append(metadata or {})
        
        return len(self.image_database) - 1
    
    def add_images_batch(self, images: List[Image.Image], metadata_list: List[Dict] = None):
        """æ‰¹é‡æ·»åŠ å›¾åƒåˆ°æ•°æ®åº“"""
        if metadata_list is None:
            metadata_list = [{}] * len(images)
        
        # æ‰¹é‡æå–ç‰¹å¾
        batch_features = self.extractor.extract_features_batch(images)
        
        for i, (image, features, metadata) in enumerate(zip(images, batch_features, metadata_list)):
            self.image_database.append(image)
            self.feature_database.append(features.cpu().numpy())
            self.metadata_database.append(metadata)
    
    def search_similar(self, query_image: Image.Image, top_k: int = 5) -> List[Tuple[int, float]]:
        """æœç´¢ç›¸ä¼¼å›¾åƒ"""
        if not self.feature_database:
            return []
        
        # æå–æŸ¥è¯¢å›¾åƒç‰¹å¾
        query_features = self.extractor.extract_features(query_image).cpu().numpy()
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = cosine_similarity([query_features], self.feature_database)[0]
        
        # è·å–top-kç»“æœ
        top_indices = np.argsort(similarities)[::-1][:top_k]
        results = [(idx, similarities[idx]) for idx in top_indices]
        
        return results
    
    def save_database(self, filepath: str):
        """ä¿å­˜ç‰¹å¾æ•°æ®åº“"""
        database = {
            'features': [f.tolist() for f in self.feature_database],
            'metadata': self.metadata_database
        }
        
        with open(filepath, 'w') as f:
            json.dump(database, f)
    
    def load_database(self, filepath: str):
        """åŠ è½½ç‰¹å¾æ•°æ®åº“"""
        with open(filepath, 'r') as f:
            database = json.load(f)
        
        self.feature_database = [np.array(f) for f in database['features']]
        self.metadata_database = database['metadata']


def create_diverse_images(num_images: int = 20) -> List[Tuple[Image.Image, str]]:
    """åˆ›å»ºå¤šæ ·åŒ–çš„æµ‹è¯•å›¾åƒ"""
    images = []
    
    # åˆ›å»ºä¸åŒç±»å‹çš„å›¾åƒ
    for i in range(num_images):
        # åˆ›å»º224x224çš„å›¾åƒ
        image = Image.new('RGB', (224, 224))
        draw = ImageDraw.Draw(image)
        
        if i < 5:  # çº¢è‰²ç³»åˆ—
            color = (255, i * 50, i * 30)
            draw.rectangle([0, 0, 224, 224], fill=color)
            category = "red_series"
        elif i < 10:  # è“è‰²ç³»åˆ—
            color = (i * 30, i * 40, 255)
            draw.rectangle([0, 0, 224, 224], fill=color)
            category = "blue_series"
        elif i < 15:  # å‡ ä½•å›¾å½¢
            color = (i * 15, 255 - i * 10, i * 20)
            draw.ellipse([50, 50, 174, 174], fill=color)
            category = "geometric"
        else:  # æ¸å˜å›¾åƒ
            for y in range(224):
                color_val = int(255 * y / 224)
                draw.line([(0, y), (224, y)], fill=(color_val, 255 - color_val, i * 10))
            category = "gradient"
        
        # æ·»åŠ æ–‡æœ¬æ ‡è¯†
        try:
            draw.text((10, 10), f"Img {i}", fill=(255, 255, 255))
        except:
            pass  # å¦‚æœæ²¡æœ‰å­—ä½“ï¼Œè·³è¿‡æ–‡æœ¬
        
        images.append((image, category))
    
    return images


def demonstrate_similarity_search():
    """æ¼”ç¤ºå›¾åƒç›¸ä¼¼åº¦æœç´¢"""
    print("=== å›¾åƒç›¸ä¼¼åº¦æœç´¢æ¼”ç¤º ===")
    
    # åˆå§‹åŒ–
    extractor = FeatureExtractor()
    search_engine = ImageSimilaritySearch(extractor)
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒæ•°æ®åº“
    print("åˆ›å»ºæµ‹è¯•å›¾åƒæ•°æ®åº“...")
    test_images = create_diverse_images(20)
    
    # æ·»åŠ å›¾åƒåˆ°æœç´¢å¼•æ“
    start_time = time.time()
    for i, (image, category) in enumerate(test_images):
        metadata = {'id': i, 'category': category, 'name': f'image_{i}'}
        search_engine.add_image(image, metadata)
    
    build_time = time.time() - start_time
    print(f"æ•°æ®åº“æ„å»ºå®Œæˆï¼Œè€—æ—¶: {build_time:.4f}ç§’")
    print(f"æ•°æ®åº“å¤§å°: {len(search_engine.image_database)}å¼ å›¾åƒ")
    
    # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
    query_image, query_category = test_images[2]  # ä½¿ç”¨ç¬¬3å¼ å›¾åƒä½œä¸ºæŸ¥è¯¢
    print(f"\næŸ¥è¯¢å›¾åƒç±»åˆ«: {query_category}")
    
    start_time = time.time()
    similar_results = search_engine.search_similar(query_image, top_k=5)
    search_time = time.time() - start_time
    
    print(f"æœç´¢å®Œæˆï¼Œè€—æ—¶: {search_time:.4f}ç§’")
    print("\nç›¸ä¼¼å›¾åƒç»“æœ:")
    for rank, (idx, similarity) in enumerate(similar_results, 1):
        metadata = search_engine.metadata_database[idx]
        print(f"  {rank}. å›¾åƒID: {metadata['id']}, ç±»åˆ«: {metadata['category']}, ç›¸ä¼¼åº¦: {similarity:.4f}")
    
    # ä¿å­˜å’ŒåŠ è½½æ•°æ®åº“
    db_path = "/tmp/image_features.json"
    search_engine.save_database(db_path)
    print(f"\nç‰¹å¾æ•°æ®åº“å·²ä¿å­˜åˆ°: {db_path}")
    
    # æµ‹è¯•åŠ è½½
    new_search_engine = ImageSimilaritySearch(extractor)
    new_search_engine.load_database(db_path)
    print(f"æ•°æ®åº“åŠ è½½æˆåŠŸï¼ŒåŒ…å«{len(new_search_engine.feature_database)}ä¸ªç‰¹å¾å‘é‡")
    
    print()


def demonstrate_image_clustering():
    """æ¼”ç¤ºå›¾åƒèšç±»"""
    print("=== å›¾åƒèšç±»æ¼”ç¤º ===")
    
    # åˆå§‹åŒ–
    extractor = FeatureExtractor()
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    print("åˆ›å»ºæµ‹è¯•å›¾åƒ...")
    test_images = create_diverse_images(16)
    images = [img for img, _ in test_images]
    categories = [cat for _, cat in test_images]
    
    # æå–ç‰¹å¾
    print("æå–å›¾åƒç‰¹å¾...")
    start_time = time.time()
    features = extractor.extract_features_batch(images, batch_size=8)
    extraction_time = time.time() - start_time
    
    print(f"ç‰¹å¾æå–å®Œæˆï¼Œè€—æ—¶: {extraction_time:.4f}ç§’")
    print(f"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {features.shape}")
    
    # æ‰§è¡Œèšç±»
    print("\næ‰§è¡ŒK-meansèšç±»...")
    n_clusters = 4
    features_np = features.cpu().numpy()
    
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(features_np)
    
    # åˆ†æèšç±»ç»“æœ
    print(f"èšç±»å®Œæˆï¼Œåˆ†ä¸º{n_clusters}ä¸ªç°‡")
    
    cluster_analysis = {}
    for i in range(n_clusters):
        cluster_indices = np.where(cluster_labels == i)[0]
        cluster_categories = [categories[idx] for idx in cluster_indices]
        cluster_analysis[i] = {
            'size': len(cluster_indices),
            'images': cluster_indices.tolist(),
            'categories': cluster_categories
        }
    
    print("\nèšç±»ç»“æœåˆ†æ:")
    for cluster_id, info in cluster_analysis.items():
        print(f"  ç°‡ {cluster_id}: {info['size']}å¼ å›¾åƒ")
        category_counts = {}
        for cat in info['categories']:
            category_counts[cat] = category_counts.get(cat, 0) + 1
        print(f"    ç±»åˆ«åˆ†å¸ƒ: {category_counts}")
        print(f"    å›¾åƒç´¢å¼•: {info['images']}")
    
    # è®¡ç®—èšç±»è´¨é‡æŒ‡æ ‡
    from sklearn.metrics import silhouette_score
    silhouette_avg = silhouette_score(features_np, cluster_labels)
    print(f"\nèšç±»è´¨é‡ (è½®å»“ç³»æ•°): {silhouette_avg:.4f}")
    
    print()


def demonstrate_large_scale_processing():
    """æ¼”ç¤ºå¤§è§„æ¨¡å›¾åƒå¤„ç†"""
    print("=== å¤§è§„æ¨¡å›¾åƒå¤„ç†æ¼”ç¤º ===")
    
    # åˆå§‹åŒ–
    extractor = FeatureExtractor()
    
    # æ¨¡æ‹Ÿå¤§è§„æ¨¡å›¾åƒå¤„ç†
    batch_sizes = [1, 8, 16, 32]
    num_images = 100
    
    print(f"æµ‹è¯•å¤„ç†{num_images}å¼ å›¾åƒï¼Œä¸åŒæ‰¹å¤„ç†å¤§å°çš„æ€§èƒ½...")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_images = []
    for i in range(num_images):
        # åˆ›å»ºç®€å•çš„æµ‹è¯•å›¾åƒ
        image_array = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
        test_images.append(Image.fromarray(image_array))
    
    results = {}
    
    for batch_size in batch_sizes:
        print(f"\næµ‹è¯•æ‰¹å¤„ç†å¤§å°: {batch_size}")
        
        start_time = time.time()
        
        if batch_size == 1:
            # å•å¼ å¤„ç†
            all_features = []
            for img in test_images:
                features = extractor.extract_features(img)
                all_features.append(features)
            final_features = torch.stack(all_features)
        else:
            # æ‰¹é‡å¤„ç†
            final_features = extractor.extract_features_batch(test_images, batch_size=batch_size)
        
        processing_time = time.time() - start_time
        
        results[batch_size] = {
            'time': processing_time,
            'throughput': num_images / processing_time,
            'features_shape': final_features.shape
        }
        
        print(f"  å¤„ç†æ—¶é—´: {processing_time:.4f}ç§’")
        print(f"  ååé‡: {num_images/processing_time:.2f}å¼ /ç§’")
        print(f"  ç‰¹å¾å½¢çŠ¶: {final_features.shape}")
    
    # æ€§èƒ½æ€»ç»“
    print("\næ€§èƒ½æ€»ç»“:")
    best_batch_size = max(results.keys(), key=lambda x: results[x]['throughput'])
    print(f"æœ€ä½³æ‰¹å¤„ç†å¤§å°: {best_batch_size} ({results[best_batch_size]['throughput']:.2f}å¼ /ç§’)")
    
    # æ˜¾ç¤ºæ€§èƒ½æå‡
    single_throughput = results[1]['throughput']
    best_throughput = results[best_batch_size]['throughput']
    speedup = best_throughput / single_throughput
    print(f"ç›¸æ¯”å•å¼ å¤„ç†æé€Ÿ: {speedup:.2f}x")
    
    print()


def demonstrate_feature_analysis():
    """æ¼”ç¤ºç‰¹å¾å‘é‡åˆ†æ"""
    print("=== ç‰¹å¾å‘é‡åˆ†ææ¼”ç¤º ===")
    
    # åˆå§‹åŒ–
    extractor = FeatureExtractor()
    
    # åˆ›å»ºä¸åŒç±»å‹çš„å›¾åƒ
    test_cases = [
        ("çº¯çº¢è‰²", Image.new('RGB', (224, 224), (255, 0, 0))),
        ("çº¯è“è‰²", Image.new('RGB', (224, 224), (0, 0, 255))),
        ("çº¯ç»¿è‰²", Image.new('RGB', (224, 224), (0, 255, 0))),
        ("ç™½è‰²", Image.new('RGB', (224, 224), (255, 255, 255))),
        ("é»‘è‰²", Image.new('RGB', (224, 224), (0, 0, 0))),
    ]
    
    # æ·»åŠ å™ªå£°å›¾åƒ
    noise_array = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
    test_cases.append(("éšæœºå™ªå£°", Image.fromarray(noise_array)))
    
    print("åˆ†æä¸åŒç±»å‹å›¾åƒçš„ç‰¹å¾å‘é‡...")
    
    features_dict = {}
    for name, image in test_cases:
        features = extractor.extract_features(image)
        features_dict[name] = features.cpu().numpy()
        
        print(f"\n{name}:")
        print(f"  ç‰¹å¾èŒƒå›´: [{features.min():.4f}, {features.max():.4f}]")
        print(f"  ç‰¹å¾å‡å€¼: {features.mean():.4f}")
        print(f"  ç‰¹å¾æ ‡å‡†å·®: {features.std():.4f}")
        print(f"  éé›¶ç‰¹å¾æ•°: {(features != 0).sum().item()}/512")
    
    # è®¡ç®—ç‰¹å¾ç›¸ä¼¼åº¦çŸ©é˜µ
    print("\nç‰¹å¾ç›¸ä¼¼åº¦çŸ©é˜µ:")
    names = list(features_dict.keys())
    features_matrix = np.array(list(features_dict.values()))
    similarity_matrix = cosine_similarity(features_matrix)
    
    print("\t" + "\t".join([name[:8] for name in names]))
    for i, name in enumerate(names):
        row = [f"{similarity_matrix[i][j]:.3f}" for j in range(len(names))]
        print(f"{name[:8]}\t" + "\t".join(row))
    
    print()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é«˜çº§åº”ç”¨æ¼”ç¤º - Mac Mç³»åˆ—èŠ¯ç‰‡ä¼˜åŒ–ç‰ˆ")
    print("=" * 50)
    
    try:
        # å›¾åƒç›¸ä¼¼åº¦æœç´¢æ¼”ç¤º
        demonstrate_similarity_search()
        
        # å›¾åƒèšç±»æ¼”ç¤º
        demonstrate_image_clustering()
        
        # å¤§è§„æ¨¡å¤„ç†æ¼”ç¤º
        demonstrate_large_scale_processing()
        
        # ç‰¹å¾åˆ†ææ¼”ç¤º
        demonstrate_feature_analysis()
        
        print("ğŸ‰ æ‰€æœ‰é«˜çº§æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ’¡ åº”ç”¨åœºæ™¯:")
        print("1. å›¾åƒæœç´¢å¼•æ“ - ä»¥å›¾æœå›¾åŠŸèƒ½")
        print("2. å›¾åƒèšç±» - è‡ªåŠ¨åˆ†ç±»å’Œç»„ç»‡")
        print("3. å†…å®¹æ¨è - åŸºäºè§†è§‰ç›¸ä¼¼åº¦çš„æ¨è")
        print("4. é‡å¤å›¾åƒæ£€æµ‹ - æ‰¾å‡ºç›¸ä¼¼æˆ–é‡å¤çš„å›¾åƒ")
        print("5. å›¾åƒæ•°æ®åº“ç´¢å¼• - å¿«é€Ÿæ£€ç´¢å’ŒåŒ¹é…")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()